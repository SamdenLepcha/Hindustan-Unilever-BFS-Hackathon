{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hindustan Uniliver Hackathon</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing useful libraries and data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"Sales_Services_July 2019.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Converting to dates to pandas datetime format</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sold On']=pd.to_datetime(data['Sold On'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Serviced On']=pd.to_datetime(data['Serviced On'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Day']=pd.DatetimeIndex(data['Closed On']).day\n",
    "#data['Day']= pd.DatetimeIndex(data['Serviced On']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Day']=data['Day'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature Engineering and Generation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Payment Type\n",
    "p = pd.DataFrame(data['Payment Type'].unique(), columns={'Payment Type'})\n",
    "data['Payment Type'].fillna('-999', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The payment column had a lot of unique values. Dropping this coliumn didn't make sense as it was important for \n",
    "# anomayly detection.Therefore we tried to shrink the number of variables to broader categories.\n",
    "payment_method = []\n",
    "methods = ['Cash', 'Visa', 'Mastercard', 'Debit Card']\n",
    "methods1 = ['Membership', 'Custom', 'coupon']\n",
    "for i in data['Payment Type']:\n",
    "    if i=='Cash':\n",
    "        payment_method.append('Cash')\n",
    "    elif i=='Visa':\n",
    "        payment_method.append('Visa')\n",
    "    elif i=='Mastercard':\n",
    "        payment_method.append('Mastercard')\n",
    "    elif i=='Debit Card':\n",
    "        payment_method.append('Debit Card')\n",
    "    elif i == '-999':\n",
    "        payment_method.append('Unknown')\n",
    "    else:\n",
    "        flag_mem = 0\n",
    "        flag_custom = 0\n",
    "        flag_coupon = 0\n",
    "        flag_other = 0\n",
    "        l = list(i.split())\n",
    "        for j in range(len(l)):\n",
    "            if l[j] in methods:\n",
    "                flag_other = 1\n",
    "            if l[j]=='Custom':\n",
    "                flag_custom = 1\n",
    "            if l[j]=='coupon':\n",
    "                flag_coupon = 1\n",
    "            if l[j]=='Membership':\n",
    "                flag_mem = 1\n",
    "        if flag_other == 1 and (flag_coupon == 1 or flag_custom == 1 or flag_mem == 1):\n",
    "            payment_method.append('Double')\n",
    "        elif flag_coupon == 1 and flag_other == 0:\n",
    "            payment_method.append('Coupon')\n",
    "        elif flag_custom == 1 and flag_other == 0:\n",
    "            payment_method.append('Custom')\n",
    "        elif flag_mem == 1 and flag_other == 0:\n",
    "            payment_method.append('Membership')\n",
    "        else:\n",
    "            payment_method.append('Others')\n",
    "#     elif 'Membership' in str(i):\n",
    "#         payment_method.append('Membership')\n",
    "#     elif 'Custom' in str(i):\n",
    "#         payment_method.append('Custom')\n",
    "#     elif i.isna():\n",
    "#         payment_method.append('None')\n",
    "#     else:\n",
    "#         payment_method.append('Double')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Store_Day']=data['Center Name']+\"_\"+(data['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Number of services daywise in a store\n",
    "groupbytot=data.groupby('Store_Day')['ServiceName'].count()\n",
    "data['total_Serv']=data['Store_Day'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Number of services avg monthly in a store\n",
    "groupbyavg=data.groupby('Center Name')['ServiceName'].count()\n",
    "data['Avg_Serv']=data['Center Name'].map(groupbyavg)\n",
    "data['Avg_Serv']=data['Avg_Serv']/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total No of Invoices in a store in a day\n",
    "groupbytot=data.groupby('Store_Day')['Invoice No'].nunique()\n",
    "data['totalInvo/Day']=data['Store_Day'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total No of Invoices in a store in a month\n",
    "groupbytot=data.groupby('Center Name')['Invoice No'].nunique()\n",
    "data['totalInvo/Month']=data['Center Name'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NetPrice0']=(data['Net Price']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NetPrice0']=data['NetPrice0'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total No of NetPrice Zeros in a store\n",
    "groupbytot=data.groupby('Center Name')['NetPrice0'].sum()\n",
    "data['NetPrice0']=data['Center Name'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Invoice No']=data['Invoice No'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store_Invoice_No_Day\n",
    "data['Store_Invoice No_Day']=data['Center Name']+\"_\"+(data['Invoice No'])+\"_\"+(data['Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Number of Unique Service Invoices in a store day wise\n",
    "groupbytot=data.groupby('Store_Invoice No_Day')['ServiceName'].nunique()\n",
    "data['UniqueService/InvoiceNo/Day/Store']=data['Store_Invoice No_Day'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Number of Repeating Invoices in a store day wise\n",
    "groupbytot=data.groupby('Store_Invoice No_Day')['Level'].count()\n",
    "data['InvoiceNo/Day/Store']=data['Store_Invoice No_Day'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store_Invoice_No_Day_Service_Name\n",
    "data['Store_Invoice No_Day_Service']=data['Center Name']+\"_\"+(data['Invoice No'])+\"_\"+(data['Day'])+\"_\"+(data['ServiceName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Number ofin a store day wise\n",
    "groupbytot=data.groupby('Store_Invoice No_Day_Service')['Level'].count()\n",
    "data['InvoiceNo/Day/Store/Service']=data['Store_Invoice No_Day_Service'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Sale value in a store per month\n",
    "groupbytot=data.groupby('Center Name')['Sale Value'].sum()\n",
    "data['totalSL/Month']=data['Center Name'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Sale value in a store average per day\n",
    "groupbytot=data.groupby('Store_Day')['Sale Value'].sum()\n",
    "data['totalSV/AvgperDay']=data['Store_Day'].map(groupbytot)\n",
    "data['totalSV/AvgperDay']=data['totalSV/AvgperDay']/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Price Paid in a store average per day\n",
    "groupbytot=data.groupby('Store_Day')['Price Paid'].sum()\n",
    "data['totalPPD/AvgperDay']=data['Store_Day'].map(groupbytot)\n",
    "data['totalPPD/AvgperDay']=data['totalPPD/AvgperDay']/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Price Paid per month in a store \n",
    "groupbytot=data.groupby('Center Name')['Price Paid'].sum()\n",
    "data['totalPPD/Month']=data['Center Name'].map(groupbytot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ClosedOnNA']=data['Closed On'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ClosedOnNA']=data['ClosedOnNA'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PromotionNA']=data['Promotion'].isna()\n",
    "data['PromotionNA']=data['PromotionNA'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Payment Method\n",
    "p_m = pd.DataFrame(payment_method, columns={'Payment Method'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Payment Method'] = p_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> For Checking </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When the Payment Type is null usually the price and discount are the same making net price zero\n",
    "#but in some cases the net price is not zero even when there is no promotion might be a cancelled transaction\n",
    "#check[check['Net Price']!=0].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check['Check'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= data.rename({'Sale Value': 'Sale_Value', 'Price Paid': 'Price_Paid'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is weird that when the Sale Value is zero and the Price Paid is zero but there is no discount but still Net Price is zero\n",
    "#data[(data.Sale_Value==0) & (data.Price_Paid!=0)].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= data.rename({'Payment Type': 'Payment_Type'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data[(data.Sale_Value==0) & (data.Price_Paid!=0) ]['Payment_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data[data['Sale_Value']==0][['Payment_Type','Sale_Value','Price_Paid']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['Sale_Value']==0].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Payment_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[(data.Payment_Type!='Cash') & (data.Payment_Type!='Visa') & (data.Payment_Type!='Mastercard') & (data.Payment_Type!='Debit Card') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['Payment_Type'].isna()].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['Promotion']=='No Promotion']['Payment_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['Payment_Type'].isna()].iloc[1]\n",
    "#['Promotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Net Price'].value_counts()\n",
    "#data['Sale Value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Sale Value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= data.rename({'Sale Value': 'Sale_Value', 'Price Paid': 'Price_Paid'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling null in promotion with No Promotion\n",
    "data['Promotion'].fillna('No Promotion',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.Promotion =='No Promotion') & (data.Discount!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['VersionId'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling Null Values in Payment Type with NA\n",
    "#data['Payment_Type'].fillna(\"NA\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check=data[data['Payment_Type'].isna()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check['Net Price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check['Net Price'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= data.rename({'Payment Type': 'Payment_Type', 'Net_Price': 'Net Price'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Payment Type'] = np.where(data['Net Price'] == 0, data['Cash'] * 0.78125, df['Budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Cashback Redemption'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Frequency Encoding Categorical Variables</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Encoding Center Name\n",
    "Center_Name=data.groupby('Center Name').size()\n",
    "Center_Name=Center_Name/len(data)\n",
    "data['Center Name FE']=data['Center Name'].map(Center_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Invoice No']=data['Invoice No'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Encoding Invoice No\n",
    "Invoice_No=data.groupby('Invoice No').size()\n",
    "Invoice_No=Invoice_No/len(data)\n",
    "data['Invoice No FE']=data['Invoice No'].map(Invoice_No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Service Name\n",
    "encoding = data.groupby('ServiceName').size()\n",
    "encoding = encoding/len(data)\n",
    "services = data['ServiceName'].map(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Services FE'] = services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding Categorical Variables with less categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=pd.get_dummies(data['Category'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat((data,category),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_Category=pd.get_dummies(data['Sub Category'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat((data,Sub_Category),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group=pd.get_dummies(data['Group'],drop_first=True)\n",
    "data=pd.concat((data,Group),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Proposition=pd.get_dummies(data['Proposition'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat((data,Proposition),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Level=pd.get_dummies(data['Level'],drop_first=True)\n",
    "data=pd.concat((data,Level),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "FocusServices=pd.get_dummies(data['FocusServices'],drop_first=True)\n",
    "data=pd.concat((data,FocusServices),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Status=pd.get_dummies(data['Status'],drop_first=True)\n",
    "data=pd.concat((data,Status),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubGroup=pd.get_dummies(data['SubGroup'],drop_first=True)\n",
    "data=pd.concat((data,SubGroup),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "AppointmentSource=pd.get_dummies(data['AppointmentSource'],drop_first=True)\n",
    "data=pd.concat((data,AppointmentSource),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstVisit=pd.get_dummies(data['FirstVisit'],drop_first=True)\n",
    "data=pd.concat((data,FirstVisit),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Member=pd.get_dummies(data['Member'],drop_first=True)\n",
    "data=pd.concat((data,Member),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Requested=pd.get_dummies(data['Requested'],drop_first=True)\n",
    "data=pd.concat((data,Requested),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PromotionNA']=data['PromotionNA'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Payment_Method=pd.get_dummies(data['Payment Method'],drop_first=True)\n",
    "data=pd.concat((data,Payment_Method),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day=pd.get_dummies(data['Day'],drop_first=True)\n",
    "data=pd.concat((data,Day),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dropping Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Removing Room and Room Category: All Null Values </p>\n",
    "<p> Removing Start and End Data: Just one repeating value </p>\n",
    "<p> Removing VersionID : 442346 null values that makes upto 99.98% of the data </p>\n",
    "<p> Removing GuestCenter: same as Center Name </p>\n",
    "<p> Membership Service Redemption,'Membership Redemption','Prepaidcard Redemption': All zeros </p>\n",
    "<p> Receiptno+Center Name=\"Receipt No\"</p>\n",
    "<p> centerrcptno+Center Name=\"Invoice No\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Level','FocusServices','Proposition','Sub Category','Category','ServiceCode','Invoice No','Center Code','centerrcptno','Receiptno','Room','Room Category','Start Date','End Date','Promotion'],axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['VersionId','GuestCenter','Membership Service Redemption','Membership Redemption','Prepaidcard Redemption','Cashback Redemption','Serviced On'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Group','SubGroup','Center Name','ServiceId','Receipt No','Sold On'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Closed On','BusinessUnit','AppointmentSource','FirstVisit','Requested','Member'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['CreatedBy'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ServiceName','SoldBy'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Payment Type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Status'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ClosedBy'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Store_Day','Store_Invoice No_Day','Store_Invoice No_Day_Service'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Payment Method'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Isolation Forest to detect anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonal/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/home/sonal/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='old', bootstrap=False, contamination='legacy',\n",
       "                max_features=1.0, max_samples=100, n_estimators=100,\n",
       "                n_jobs=None, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = IsolationForest(max_samples=100, random_state=0)\n",
    "clf.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonal/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "pred_iso = clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Isolation = pd.DataFrame(pred_iso, columns={'Isolation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    398181\n",
       "-1     44243\n",
       "Name: Isolation, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Isolation['Isolation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Isolation.to_excel('Isolation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original['Isolation'] = Isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Variational AutoEncoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=sc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "justtest=pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "justtest[\"Isolation\"]=Isolation['Isolation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonoutliers=justtest[justtest[\"Isolation\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonal/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "nonoutliers.drop(\"Isolation\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353939, 172)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(justtest, test_size=0.2)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sonal/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 14\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error')\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
